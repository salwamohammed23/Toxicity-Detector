import streamlit as st
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    BlipProcessor,
    BlipForConditionalGeneration,
    pipeline
)
from peft import PeftModel, PeftConfig
from PIL import Image
import torch
import os

# 1. ุฅุนุฏุงุฏ ุงูุชุทุจูู
st.set_page_config(
    page_title="ูุญูู ุณูุงูุฉ ุงููุญุชูู ุงููุชูุฏู",
    page_icon="๐ก๏ธ",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title("๐ก๏ธ ูุญูู ุณูุงูุฉ ุงููุญุชูู ุงููุชูุฏู")

# 2. ุชุญููู ุฌููุน ุงูููุงุฐุฌ
@st.cache_resource(show_spinner="ุฌุงุฑู ุชุญููู ุงูููุงุฐุฌ...")
def load_models():
    try:
        # ุชุญููู ูููุฐุฌ ุฅูุดุงุก ุงูุชุณููุงุช ุงูุชูุถูุญูุฉ ููุตูุฑ
        with st.spinner("ุฌุงุฑู ุชุญููู ูููุฐุฌ ูุตู ุงูุตูุฑ..."):
            blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
            blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
        
        # ุชุญููู ูููุฐุฌ ุงููุญุต ุงูุฃููู ููุณูุงูุฉ
        with st.spinner("ุฌุงุฑู ุชุญููู ูููุฐุฌ ุงููุญุต ุงูุฃููู..."):
            flan_pipe = pipeline("text2text-generation", model="google/flan-t5-base")
        
        # ุชุญููู ูููุฐุฌ ุงูุชุญููู ุงูุชูุตููู
        with st.spinner("ุฌุงุฑู ุชุญููู ูููุฐุฌ ุงูุชุญููู ุงูุชูุตููู..."):
            model_path = "Model/lora_distilbert_toxic_final"
            config = PeftConfig.from_pretrained(model_path)
            base_model = AutoModelForSequenceClassification.from_pretrained(
                config.base_model_name_or_path,
                num_labels=9,
                return_dict=True,
                ignore_mismatched_sizes=True
            )
            lora_model = PeftModel.from_pretrained(base_model, model_path)
            tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # ููู ุงูููุงุฐุฌ ุฅูู GPU ุฅุฐุง ูุงู ูุชุงุญูุง
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        blip_model.to(device)
        lora_model.to(device)
        
        return blip_processor, blip_model, flan_pipe, lora_model, tokenizer, device
    
    except Exception as e:
        st.error(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุชุญููู ุงูููุงุฐุฌ: {str(e)}")
        return None, None, None, None, None, None

blip_processor, blip_model, flan_pipe, lora_model, tokenizer, device = load_models()

# 3. ุงูุฏูุงู ุงููุณุงุนุฏุฉ
def generate_caption(image):
    """ุฅูุดุงุก ุชุณููุฉ ุชูุถูุญูุฉ ููุตูุฑุฉ"""
    try:
        raw_image = Image.open(image).convert("RGB")
        inputs = blip_processor(raw_image, return_tensors="pt").to(device)
        out = blip_model.generate(**inputs)
        return blip_processor.decode(out[0], skip_special_tokens=True)
    except Exception as e:
        st.error(f"ูุดู ูู ูุนุงูุฌุฉ ุงูุตูุฑุฉ: {str(e)}")
        return None

def initial_safety_check(text):
    """ูุญุต ุงูุณูุงูุฉ ุงูุฃููู"""
    prompt = f"ูู ูุฐุง ุงููุญุชูู ุขูู ุฃู ุบูุฑ ุขููุ \"{text}\" ุฃุฌุจ ุจูููุฉ ูุงุญุฏุฉ ููุท: ุขูู ุฃู ุบูุฑ ุขูู."
    result = flan_pipe(prompt, max_new_tokens=10)
    return result[0]['generated_text'].strip().lower()

def detailed_analysis(text):
    """ุชุญููู ุชูุตููู ูููุญุชูู"""
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    ).to(device)
    
    with torch.no_grad():
        outputs = lora_model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    
    return probs[0].tolist()

# 4. ุชุนุฑูู ุงูุชุตูููุงุช
LABELS = {
    0: {"name": "ุขูู", "emoji": "โ", "color": "green"},
    1: {"name": "ุฎุทุงุจ ูุฑุงููุฉ", "emoji": "๐ข", "color": "red"},
    2: {"name": "ุฅูุงูุฉ", "emoji": "๐ฏ๏ธ", "color": "orange"},
    3: {"name": "ุชูุฏูุฏ", "emoji": "โ๏ธ", "color": "red"},
    4: {"name": "ุนูุตุฑู", "emoji": "๐ซ", "color": "red"},
    5: {"name": "ุฌูุณู", "emoji": "๐", "color": "red"},
    6: {"name": "ุชุญุฑูุถ", "emoji": "๐ฅ", "color": "orange"},
    7: {"name": "ุฃุฎุฑู", "emoji": "โ", "color": "gray"},
    8: {"name": "ุฅูุฐุงุก ุฐุงุชู", "emoji": "๐", "color": "red"}
}

# 5. ูุงุฌูุฉ ุงููุณุชุฎุฏู
with st.form("content_form"):
    input_type = st.radio(
        "ุงุฎุชุฑ ููุน ุงููุญุชูู:",
        ["ูุต", "ุตูุฑุฉ"],
        horizontal=True
    )
    
    if input_type == "ูุต":
        content = st.text_area(
            "ุฃุฏุฎู ุงููุต ููุชุญููู:",
            height=200,
            placeholder="ุงูุตู ุงููุต ููุง..."
        )
    else:
        content = st.file_uploader(
            "ุฑูุน ุตูุฑุฉ ููุชุญููู:",
            type=["jpg", "jpeg", "png"]
        )
    
    submitted = st.form_submit_button("ุชุญููู ุงููุญุชูู", use_container_width=True)

# 6. ูุนุงูุฌุฉ ุงููุญุชูู
if submitted:
    if (input_type == "ุตูุฑุฉ" and content is not None) or (input_type == "ูุต" and content.strip() != ""):
        with st.spinner("ุฌุงุฑู ุชุญููู ุงููุญุชูู..."):
            try:
                # ุงููุฑุญูุฉ 1: ุงูุญุตูู ุนูู ุงููุต (ุฅูุง ูุจุงุดุฑุฉ ุฃู ูู ูุตู ุงูุตูุฑุฉ)
                if input_type == "ุตูุฑุฉ":
                    st.image(content, caption="ุงูุตูุฑุฉ ุงููุฑููุนุฉ", use_column_width=True)
                    caption = generate_caption(content)
                    if caption is None:
                        st.stop()
                    
                    st.success(f"ุงูุชุณููุฉ ุงูุชูุถูุญูุฉ ุงููููุฏุฉ: {caption}")
                    text_to_analyze = caption
                else:
                    text_to_analyze = content
                
                # ุงููุฑุญูุฉ 2: ุงููุญุต ุงูุฃููู ููุณูุงูุฉ
                initial_check = initial_safety_check(text_to_analyze)
                
                if "ุบูุฑ ุขูู" in initial_check:
                    st.error("## โ ุงููุญุต ุงูุฃููู: ูุญุชูู ุบูุฑ ุขูู")
                    st.error("ุชู ุงูุชุดุงู ูุญุชูู ุบูุฑ ุขูู ูู ุงููุญุต ุงูุฃููู.")
                    st.stop()
                
                # ุงููุฑุญูุฉ 3: ุงูุชุญููู ุงูุชูุตููู
                st.success("## โ ุงููุญุต ุงูุฃููู: ูุญุชูู ุขูู")
                st.info("ุฌุงุฑู ุงูุชุญููู ุงูุชูุตููู...")
                
                probs = detailed_analysis(text_to_analyze)
                pred_idx = max(range(len(probs)), key=lambda i: probs[i])
                confidence = probs[pred_idx]
                label = LABELS[pred_idx]
                
                # ุนุฑุถ ุงููุชุงุฆุฌ
                st.subheader("๐ ูุชุงุฆุฌ ุงูุชุญููู ุงูุชูุตููู")
                st.success(f"""
                ## {label['emoji']} ุงูุชุตููู: **{label['name']}**  
                **ูุณุชูู ุงูุซูุฉ**: {confidence:.2%}  
                **ุงูุชูููู**: {"ุบูุฑ ุขูู" if pred_idx > 0 else "ุขูู"}
                """)
                
                # ุชูุฒูุน ุงูุงุญุชูุงูุงุช
                st.markdown("### ุชูุฒูุน ุงูุงุญุชูุงูุงุช ุญุณุจ ุงููุฆุฉ")
                for i, prob in enumerate(probs):
                    label_info = LABELS[i]
                    cols = st.columns([1, 3, 1])
                    cols[0].markdown(f"**{label_info['emoji']} {label_info['name']}**")
                    cols[1].progress(
                        prob,
                        text=f"{prob:.2%}"
                    )
                    cols[2].markdown(f"`{prob:.2%}`")
            
            except Exception as e:
                st.error(f"ุญุฏุซ ุฎุทุฃ ุฃุซูุงุก ุงูุชุญููู: {str(e)}")
    else:
        st.warning("ุงูุฑุฌุงุก ุฅุฏุฎุงู ูุต ุฃู ุฑูุน ุตูุฑุฉ")

# 7. ูุนูููุงุช ุฅุถุงููุฉ
st.sidebar.markdown("## ๐๏ธ ูุนูููุงุช ุชูููุฉ")
st.sidebar.info("""
**ุฎุทูุงุช ุงูุชุญููู:**
1. BLIP (ูุตู ุงูุตูุฑ)
2. FLAN-T5 (ูุญุต ุฃููู)
3. DistilBERT (ุชุญููู ุชูุตููู)

**ูุฆุงุช ุงูุชุตููู:**
- โ ุขูู
- ๐ข ุฎุทุงุจ ูุฑุงููุฉ
- ๐ฏ๏ธ ุฅูุงูุฉ
- โ๏ธ ุชูุฏูุฏ
- ๐ซ ุนูุตุฑู
- ๐ ุฌูุณู
- ๐ฅ ุชุญุฑูุถ
- โ ุฃุฎุฑู
- ๐ ุฅูุฐุงุก ุฐุงุชู
""")

# 8. ุชุฐููู ุงูุตูุญุฉ
st.markdown("---")
st.markdown("""
<style>
.footer {
    text-align: center;
    padding: 10px;
    font-size: 12px;
}
</style>
<div class="footer">
    <p>ูุญูู ุณูุงูุฉ ุงููุญุชูู ุงููุชูุฏู | ุญูุงูุฉ ุจูุงุณุทุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู</p>
</div>
""", unsafe_allow_html=True)
