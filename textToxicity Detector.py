import streamlit as st
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    BlipProcessor,
    BlipForConditionalGeneration,
    pipeline
)
from peft import PeftModel, PeftConfig
from PIL import Image
import torch
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(
    page_title="Ù…Ø­Ù„Ù„ Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title("ğŸ›¡ï¸ Ù…Ø­Ù„Ù„ Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
@st.cache_resource(show_spinner="Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
def load_models():
    try:
        # Ù†Ù…ÙˆØ°Ø¬ ÙˆØµÙ Ø§Ù„ØµÙˆØ±
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ÙˆØµÙ Ø§Ù„ØµÙˆØ±..."):
            blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
            blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
        
        # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ..."):
            flan_pipe = pipeline("text2text-generation", model="google/flan-t5-base")
        
        # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ..."):
            model_path = "Model/lora_distilbert_toxic_final"
            config = PeftConfig.from_pretrained(model_path)
            base_model = AutoModelForSequenceClassification.from_pretrained(
                config.base_model_name_or_path,
                num_labels=9,
                return_dict=True,
                ignore_mismatched_sizes=True
            )
            lora_model = PeftModel.from_pretrained(base_model, model_path)
            tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù€ GPU Ø¥Ø°Ø§ Ù…ØªØ§Ø­
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        blip_model.to(device)
        lora_model.to(device)
        
        return blip_processor, blip_model, flan_pipe, lora_model, tokenizer, device
    
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {str(e)}")
        return None, None, None, None, None, None

# ØªØ¹Ø±ÙŠÙ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
LABELS = {
    0: {"name": "Ø¢Ù…Ù†", "emoji": "âœ…", "color": "green"},
    1: {"name": "Ø®Ø·Ø§Ø¨ ÙƒØ±Ø§Ù‡ÙŠØ©", "emoji": "ğŸ’¢", "color": "red"},
    2: {"name": "Ø¥Ù‡Ø§Ù†Ø©", "emoji": "ğŸ—¯ï¸", "color": "orange"},
    3: {"name": "ØªÙ‡Ø¯ÙŠØ¯", "emoji": "âš ï¸", "color": "red"},
    4: {"name": "Ø¹Ù†ØµØ±ÙŠ", "emoji": "ğŸš«", "color": "red"},
    5: {"name": "Ø¬Ù†Ø³ÙŠ", "emoji": "ğŸ”", "color": "red"},
    6: {"name": "ØªØ­Ø±ÙŠØ¶", "emoji": "ğŸ”¥", "color": "orange"},
    7: {"name": "Ø£Ø®Ø±Ù‰", "emoji": "â“", "color": "gray"},
    8: {"name": "Ø¥ÙŠØ°Ø§Ø¡ Ø°Ø§ØªÙŠ", "emoji": "ğŸ’”", "color": "red"}
}

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
def analyze_text(text, lora_model, tokenizer, device):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    ).to(device)
    
    with torch.no_grad():
        outputs = lora_model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    
    return probs[0].tolist()

def main():
    blip_processor, blip_model, flan_pipe, lora_model, tokenizer, device = load_models()
    
    # Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
    if st.button("ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙØ­Ø©"):
        st.experimental_rerun()
    
    input_type = st.radio(
        "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:",
        ["Ù†Øµ", "ØµÙˆØ±Ø©"],
        horizontal=True,
        key="input_type"
    )
    
    if input_type == "ØµÙˆØ±Ø©":
        uploaded_file = st.file_uploader(
            "Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:",
            type=["jpg", "jpeg", "png"],
            key="image_uploader"
        )
        
        if uploaded_file is not None:
            st.image(uploaded_file, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©", use_column_width=True)
            
            if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©", key="analyze_image"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©..."):
                    try:
                        raw_image = Image.open(uploaded_file).convert("RGB")
                        inputs = blip_processor(raw_image, return_tensors="pt").to(device)
                        out = blip_model.generate(**inputs)
                        caption = blip_processor.decode(out[0], skip_special_tokens=True)
                        
                        st.success(f"**Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©:** {caption}")
                        
                        probs = analyze_text(caption, lora_model, tokenizer, device)
                        pred_idx = probs.index(max(probs))
                        confidence = probs[pred_idx]
                        label = LABELS[pred_idx]
                        
                        st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
                        st.markdown(f"""
                        <div style='background-color:#f0f0f0; padding:15px; border-radius:10px; border-left:5px solid {label["color"]}'>
                            <h3 style='color:{label["color"]}'>{label["emoji"]} Ø§Ù„ØªØµÙ†ÙŠÙ: <strong>{label["name"]}</strong></h3>
                            <p>Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {confidence:.2%}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.write("### ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:")
                        for i, prob in enumerate(probs):
                            label_info = LABELS[i]
                            cols = st.columns([1, 3, 1])
                            cols[0].markdown(f"**{label_info['emoji']} {label_info['name']}**")
                            cols[1].progress(prob, text=f"{prob:.2%}")
                            cols[2].write(f"{prob:.2%}")
                            
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
    
    elif input_type == "Ù†Øµ":
        text_content = st.text_area(
            "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„:",
            height=200,
            placeholder="Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§...",
            key="text_input"
        )
        
        if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ", key="analyze_text"):
            if not text_content.strip():
                st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„")
            else:
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ..."):
                    try:
                        # Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ
                        initial_check = initial_safety_check(text_content, flan_pipe)
                        
                        if "ØºÙŠØ± Ø¢Ù…Ù†" in initial_check.lower():
                            st.error("## âŒ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ: Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø¢Ù…Ù†")
                            st.error("ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø¢Ù…Ù† ÙÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ.")
                        else:
                            st.success("## âœ… Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£ÙˆÙ„ÙŠ: Ù…Ø­ØªÙˆÙ‰ Ø¢Ù…Ù†")
                            st.info("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ...")
                            
                            probs = analyze_text(text_content, lora_model, tokenizer, device)
                            pred_idx = probs.index(max(probs))
                            confidence = probs[pred_idx]
                            label = LABELS[pred_idx]
                            
                            st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
                            st.markdown(f"""
                            <div style='background-color:#f0f0f0; padding:15px; border-radius:10px; border-left:5px solid {label["color"]}'>
                                <h3 style='color:{label["color"]}'>{label["emoji"]} Ø§Ù„ØªØµÙ†ÙŠÙ: <strong>{label["name"]}</strong></h3>
                                <p>Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {confidence:.2%}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            st.write("### ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:")
                            for i, prob in enumerate(probs):
                                label_info = LABELS[i]
                                cols = st.columns([1, 3, 1])
                                cols[0].markdown(f"**{label_info['emoji']} {label_info['name']}**")
                                cols[1].progress(prob, text=f"{prob:.2%}")
                                cols[2].write(f"{prob:.2%}")
                    
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {str(e)}")

def initial_safety_check(text, flan_pipe):
    prompt = f"Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¢Ù…Ù† Ø£Ù… ØºÙŠØ± Ø¢Ù…Ù†ØŸ \"{text}\" Ø£Ø¬Ø¨ Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·: Ø¢Ù…Ù† Ø£Ùˆ ØºÙŠØ± Ø¢Ù…Ù†."
    result = flan_pipe(prompt, max_new_tokens=10)
    return result[0]['generated_text'].strip()

if __name__ == "__main__":
    main()
